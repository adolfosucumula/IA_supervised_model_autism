{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #toolbox to work with dataframes\n",
    "import numpy as np #toolbox to work with narrays\n",
    "import matplotlib.pyplot as plt #toolbox to do plots\n",
    "from sklearn.svm import SVC #load the support vector machine model functions\n",
    "from sklearn.model_selection import train_test_split #load the function to split train and test sets\n",
    "from sklearn import metrics # get the report\n",
    "from sklearn.metrics import classification_report # get the report\n",
    "from sklearn import preprocessing # normalize the features\n",
    "from sklearn.preprocessing import MinMaxScaler # normalize the features\n",
    "from sklearn.feature_selection import SelectKBest #load the feature selector model  \n",
    "from sklearn.feature_selection import chi2 #feature selector algorithm\n",
    "\n",
    "\n",
    "def normalized_data (df,t):\n",
    "\n",
    "    if (t==1):\n",
    "        d=df.copy() # min max normalization\n",
    "        for each_collum in range(0,df.shape[1]):\n",
    "            max =df.iloc[:,each_collum].max()\n",
    "            min =df.iloc[:,each_collum].min()\n",
    "            d.iloc[:,each_collum]=(d.iloc[:,each_collum]-min)/(max-min)\n",
    "    elif (t==2):\n",
    "        d=df.copy() # mean normalization\n",
    "        for each_collum in range(0,df.shape[1]):\n",
    "            max =df.iloc[:,each_collum].max()\n",
    "            min =df.iloc[:,each_collum].min()\n",
    "            mean =df.iloc[:,each_collum].mean()\n",
    "            d.iloc[:,each_collum]=(d.iloc[:,each_collum]-mean)/(max-min)\n",
    "    \n",
    "    else:\n",
    "        d=df.copy() # standardization\n",
    "        for each_collum in range(0,df.shape[1]):\n",
    "            mean =df.iloc[:,each_collum].mean()\n",
    "            std =df.iloc[:,each_collum].std()\n",
    "            d.iloc[:,each_collum]=(d.iloc[:,each_collum]-mean)/(std)\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prodrigues\\AppData\\Local\\Temp\\ipykernel_11464\\31263044.py:2: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df = pd.read_csv('winequality-white.csv',';') #open the database\n"
     ]
    }
   ],
   "source": [
    "# 1st step database opening\n",
    "df = pd.read_csv('winequality-white.csv',';') #open the database\n",
    "\n",
    "# split the database in target and features\n",
    "target=df.iloc[:,-1]\n",
    "df=df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd step - features normalization\n",
    "d_n=normalized_data (df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd step - load and design the classifiers\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier,ExtraTreesClassifier,RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "classifiers = [\n",
    "    SVC(gamma='auto'),\n",
    "    GaussianProcessClassifier(1.0* RBF(1.0)),\n",
    "    LinearSVC(),\n",
    "    SGDClassifier(),\n",
    "    KNeighborsClassifier(),\n",
    "    LogisticRegression(solver='lbfgs'),\n",
    "    LogisticRegressionCV(cv=3),\n",
    "    BaggingClassifier(),\n",
    "    ExtraTreesClassifier(n_estimators=300),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=300, max_features=1),\n",
    "    GaussianNB(),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    MLPClassifier(alpha=1,max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    OneVsRestClassifier(LinearSVC(random_state=0)),\n",
    "    GradientBoostingClassifier(),\n",
    "    SGDClassifier(),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "2501       0.250000          0.225490     0.240964        0.088957   0.089021   \n",
      "4306       0.221154          0.156863     0.162651        0.167178   0.121662   \n",
      "1779       0.250000          0.068627     0.216867        0.018405   0.074184   \n",
      "2167       0.346154          0.107843     0.180723        0.187117   0.130564   \n",
      "4855       0.317308          0.147059     0.234940        0.200920   0.145401   \n",
      "...             ...               ...          ...             ...        ...   \n",
      "2929       0.269231          0.137255     0.174699        0.211656   0.109792   \n",
      "283        0.278846          0.254902     0.180723        0.230061   0.133531   \n",
      "4124       0.211538          0.049020     0.216867        0.015337   0.127596   \n",
      "450        0.326923          0.509804     0.120482        0.142638   0.181009   \n",
      "3840       0.278846          0.284314     0.150602        0.029141   0.056380   \n",
      "\n",
      "      free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
      "2501             0.128920              0.422274  0.154617  0.381818   \n",
      "4306             0.170732              0.287703  0.147484  0.454545   \n",
      "1779             0.142857              0.327146  0.098130  0.636364   \n",
      "2167             0.162021              0.510441  0.221515  0.381818   \n",
      "4855             0.083624              0.378190  0.201272  0.163636   \n",
      "...                   ...                   ...       ...       ...   \n",
      "2929             0.128920              0.252900  0.216503  0.300000   \n",
      "283              0.170732              0.433875  0.213804  0.427273   \n",
      "4124             0.073171              0.146172  0.050704  0.345455   \n",
      "450              0.066202              0.382831  0.192597  0.281818   \n",
      "3840             0.076655              0.174014  0.073067  0.381818   \n",
      "\n",
      "      sulphates   alcohol  \n",
      "2501   0.348837  0.290323  \n",
      "4306   0.174419  0.451613  \n",
      "1779   0.546512  0.483871  \n",
      "2167   0.313953  0.177419  \n",
      "4855   0.279070  0.161290  \n",
      "...         ...       ...  \n",
      "2929   0.325581  0.177419  \n",
      "283    0.313953  0.209677  \n",
      "4124   0.325581  0.564516  \n",
      "450    0.372093  0.177419  \n",
      "3840   0.162791  0.596774  \n",
      "\n",
      "[3673 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# split data for training and testing your model\n",
    "X_train, X_test, y_train, y_test = train_test_split(d_n, target, train_size = 0.75) # 75% of data goes for training and 25% goes for testing\n",
    "\n",
    "print(X_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f681d13594f6d13fd384c1eed34ffbd142ac2c86c0f865443692fcf61f9efdbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
